import data.processed
import modules.model

# 训练步数与优化器超参数
train.iterations=1  # 只跑 1 步，用于触发评估
train.learning_rate=0.0003  # AdamW 学习率（评估时不会用到）
train.weight_decay=0.035  # AdamW 权重衰减（评估时不会用到）
train.batch_size=256  # 每步 batch 大小
train.amp=False  # 保持与训练一致的混合精度设置

# RQ‑VAE tokenizer 相关超参（需与训练时一致）
train.vae_input_dim=768
train.vae_hidden_dims=[512, 256, 128]
train.vae_embed_dim=32
train.vae_n_cat_feats=0
train.vae_codebook_size=256

# 日志与可视化
train.wandb_logging=False

# 预训练模型路径
train.pretrained_rqvae_path="trained_models/rqvae_amazon_beauty/checkpoint_399999.pt"
train.pretrained_decoder_path="out/decoder/amazon/ampon_it20000_19999.pt"

# 数据集路径与处理选项
train.save_dir_root="out/decoder/amazon/"  # 评测不保存新权重
train.dataset_folder="dataset/amazon"
train.dataset=%data.processed.RecDataset.AMAZON
train.force_dataset_process=False
train.dataset_split="beauty"

# 评估频率（步）
train.full_eval_every=1  # 每步做完整评估
train.partial_eval_every=1  # 每步做部分评估
train.save_model_every=100000000  # 不保存新 checkpoint

# Decoder Transformer 超参（需与训练时一致）
train.dropout_p=0.15
train.attn_heads=8
train.attn_embed_dim=512
train.attn_layers=8
train.decoder_embed_dim=128
train.model_jagged_mode=True

# 保存文件名前缀（评测用，不会实际保存）
train.save_name_prefix="ampon_it20000_eval"
